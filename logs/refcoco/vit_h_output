/net/per610a/export/das18a/satoh-lab/yxiao/anaconda3/envs/sam/lib/python3.8/site-packages/torch/distributed/launch.py:178: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
RANK and WORLD_SIZE in environment: 0/3
RANK and WORLD_SIZE in environment: 1/3
RANK and WORLD_SIZE in environment: 2/3
Image size: 1024
loading dataset refcoco into memory...
creating index...
index created.
DONE (t=6.56s)
loading dataset refcoco into memory...
creating index...
index created.
DONE (t=6.95s)
local rank 0 / global rank 0 successfully built train dataset.
vit_h
Epoch: [0]  [  0/151]  eta: 0:19:30  lr: 1.6000000000000003e-05  loss: 0.2525 (0.2525)  time: 7.7511  data: 2.0850  max mem: 21430
Epoch: [0]  [ 10/151]  eta: 0:11:36  lr: 0.00017600000000000002  loss: 0.2286 (0.2342)  time: 4.9366  data: 0.1959  max mem: 21472
Epoch: [0]  [ 20/151]  eta: 0:10:26  lr: 0.000336  loss: 0.2210 (0.2288)  time: 4.6301  data: 0.0071  max mem: 21472
Epoch: [0]  [ 30/151]  eta: 0:09:27  lr: 0.000496  loss: 0.2107 (0.2209)  time: 4.5502  data: 0.0075  max mem: 21472
Epoch: [0]  [ 40/151]  eta: 0:08:34  lr: 0.000656  loss: 0.2058 (0.2184)  time: 4.4905  data: 0.0076  max mem: 21472
Epoch: [0]  [ 50/151]  eta: 0:07:44  lr: 0.0008  loss: 0.2058 (0.2152)  time: 4.4647  data: 0.0076  max mem: 21472
Epoch: [0]  [ 60/151]  eta: 0:06:56  lr: 0.0008  loss: 0.1987 (0.2118)  time: 4.4544  data: 0.0077  max mem: 21472
Epoch: [0]  [ 70/151]  eta: 0:06:10  lr: 0.0008  loss: 0.1906 (0.2081)  time: 4.4923  data: 0.0076  max mem: 21472
Epoch: [0]  [ 80/151]  eta: 0:05:23  lr: 0.0008  loss: 0.1848 (0.2051)  time: 4.5151  data: 0.0076  max mem: 21472
Epoch: [0]  [ 90/151]  eta: 0:04:37  lr: 0.0008  loss: 0.1837 (0.2026)  time: 4.4954  data: 0.0075  max mem: 21472
Epoch: [0]  [100/151]  eta: 0:03:51  lr: 0.0008  loss: 0.1799 (0.1997)  time: 4.4591  data: 0.0074  max mem: 21472
Epoch: [0]  [110/151]  eta: 0:03:05  lr: 0.0008  loss: 0.1735 (0.1972)  time: 4.4360  data: 0.0074  max mem: 21472
Epoch: [0]  [120/151]  eta: 0:02:20  lr: 0.0008  loss: 0.1702 (0.1949)  time: 4.4468  data: 0.0075  max mem: 21472
Epoch: [0]  [130/151]  eta: 0:01:34  lr: 0.0008  loss: 0.1710 (0.1934)  time: 4.4562  data: 0.0075  max mem: 21472
Epoch: [0]  [140/151]  eta: 0:00:49  lr: 0.0008  loss: 0.1808 (0.1928)  time: 4.4442  data: 0.0075  max mem: 21472
Epoch: [0]  [150/151]  eta: 0:00:04  lr: 0.0008  loss: 0.1857 (0.1923)  time: 4.4426  data: 0.0075  max mem: 21472
Epoch: [0] Total time: 0:11:21
Train loss: 86.577005 (86.577005)
Test:  [   0/1810]  eta: 1:00:01    time: 1.9899  data: 1.3032  max mem: 21472
Test:  [ 100/1810]  eta: 0:18:08    time: 0.6243  data: 0.0014  max mem: 21472
Test:  [ 200/1810]  eta: 0:16:56    time: 0.6260  data: 0.0013  max mem: 21472
Test:  [ 300/1810]  eta: 0:15:50    time: 0.6261  data: 0.0014  max mem: 21472
Test:  [ 400/1810]  eta: 0:14:46    time: 0.6266  data: 0.0015  max mem: 21472
Test:  [ 500/1810]  eta: 0:13:42    time: 0.6263  data: 0.0013  max mem: 21472
Test:  [ 600/1810]  eta: 0:12:39    time: 0.6256  data: 0.0013  max mem: 21472
Test:  [ 700/1810]  eta: 0:11:36    time: 0.6258  data: 0.0013  max mem: 21472
Test:  [ 800/1810]  eta: 0:10:33    time: 0.6266  data: 0.0014  max mem: 21472
Test:  [ 900/1810]  eta: 0:09:30    time: 0.6260  data: 0.0014  max mem: 21472
Test:  [1000/1810]  eta: 0:08:27    time: 0.6258  data: 0.0014  max mem: 21472
Test:  [1100/1810]  eta: 0:07:25    time: 0.6252  data: 0.0013  max mem: 21472
Test:  [1200/1810]  eta: 0:06:22    time: 0.6262  data: 0.0014  max mem: 21472
Test:  [1300/1810]  eta: 0:05:19    time: 0.6261  data: 0.0014  max mem: 21472
Test:  [1400/1810]  eta: 0:04:16    time: 0.6255  data: 0.0014  max mem: 21472
Test:  [1500/1810]  eta: 0:03:14    time: 0.6262  data: 0.0014  max mem: 21472
